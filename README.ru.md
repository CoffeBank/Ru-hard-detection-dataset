# Ru-hard-detection-dataset [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/CoffeBank/Ru-hard-detection-dataset)

Датасет для оценки детекции сгенерированных текстов на русском языке. Он включает оригинальные человеческие тексты, версии, созданные ИИ, и их перефразирования в разных жанрах.

## Структура датасета

В корне находятся две основные директории:
- **main** – основная часть датасета, содержащая три темы:
  - **news** – новости
  - **essay** – эссе
  - **scientific_texts** – научные статьи

- **long_sc** – дополнительные тексты научных исследований

Каждый JSON-файл представляет собой список записей со следующими полями:

- `id` – уникальный идентификатор
- `text` – текст примера
- `dataset` – источник текста (например, `Lenta.ru news`)
- `source` – `human` для исходных текстов, `ai` для сгенерированных и `ai+rew` для перефразов
- `model` – модель генерации (присутствует в сгенерированных и перефразированных файлах)
- `paraphrasing_type` – степень перефразирования: `LP` (слабое) или `DP` (глубокое), если есть

В каждой из этих папок находятся три файла:
1. **Оригинал**
2. **Сгенерированный текст** – сгенерирован на основе суммаризации оригинала. Иными словами, выделили ключевую информацию из оригинального текста и использовали её как основу для генерации нового, схожего текста.
3. **Перефразированный текст** – переписанный оригинал с использованием двух вариантов: слабого и сильного перефразирования.

| Папка | Файл | Количество |
|-------|------|-----------:|
| `main/news` | `original_news.json` | 480 |
| | `generated_news.json` | 480 |
| | `paraphrased_news.json` | 480 |
| `main/essay` | `original_essay.json` | 480 |
| | `generated_essays.json` | 480 |
| | `paraphrased_essays.json` | 480 |
| `main/scientific_texts` | `orig_scientific.json` | 479 |
| | `generated_scientific.json` | 479 |
| | `paraphrased_scientific.json` | 479 |
| `long_sc` | `rus_scientific_articles_part1.json` | 1239 |
| | `rus_scientific_articles_part2.json` | 1239 |
| | `generated_articles.json` | 1449 |
| | `paraphrased_generated_articles.json` | 1625 |

## Модели и источники

Записи в JSON отражают происхождение каждого текста и модель, которая его сгенерировала.
Генерация производилась на основе кратких суммаризаций исходных текстов моделями:
`gemini-2.0-flash`, `chatgpt-4o-mini`, `chatgpt-o1-mini`, `deepseek-chat` и `deepseek-reasoner`.
Перефразирование выполнялось этими же моделями в двух режимах – `LP` (слабое) и `DP` (глубокое).
Оригинальные материалы собраны из новостей **Lenta.ru**, корпуса **Corus Essays**, датасета русских суммаризаций и подборки научных статей.

## Пример использования

Скрипт `examples/load_dataset_example.py` последовательно читает все JSON-файлы из папки `main` и выводит по одной записи из каждого. Запустите его:

```bash
python examples/load_dataset_example.py
```
